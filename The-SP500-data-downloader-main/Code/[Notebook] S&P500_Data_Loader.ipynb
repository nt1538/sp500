{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LfhzeQLV0J0o"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import yfinance as yf\n",
    "except ImportError:\n",
    "    raise ImportError(\"Cannot start without 'yfinance' package.\\nInstall it before running the code again.\")\n",
    "\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "\n",
    "class SP500DataLoader:\n",
    "    def __init__(self):\n",
    "        if not os.path.exists('Data'):\n",
    "            os.makedirs('Data')\n",
    "\n",
    "        self.start_date, self.end_date = None, None\n",
    "        self.cleaned_prices = None\n",
    "        self.cleaned_returns = None\n",
    "        self.raw_prices = None\n",
    "        self.raw_returns = None\n",
    "\n",
    "        # Download stocks names from S&P500 page on wikipedia\n",
    "        # resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        # soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "        # table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "        # self.tickers = []\n",
    "        # for row in table.findAll('tr')[1:]:\n",
    "        #     ticker = row.findAll('td')[0].text\n",
    "        #     self.tickers.append(ticker)\n",
    "        # self.tickers = [s.replace('\\n', '') for s in self.tickers]\n",
    "        # self.tickers = self.tickers + [\"SPY\"]\n",
    "        #^IXIC: Nasdaq\n",
    "        #^GSPC: sp500\n",
    "        #^RUT: russell\n",
    "        #^DJI: dow jones\n",
    "        #EFA: MSCI EAFE\n",
    "        #EEM: MSCI Emerging Markets\n",
    "        #DSI: MSCI KLD 400\n",
    "        #^STOXX50E: EURO STOXX 50\n",
    "        #US10y: ^TNX\n",
    "        #US2y: \n",
    "        #US5y: ^FVX\n",
    "        #Communication Services: XLC\n",
    "        #Consumer Discretionary: XLY\n",
    "        #Consumer Staples: XLP\n",
    "        #Energy: XLE\n",
    "        #Financials: XLF\n",
    "        #Health Care: XLV\n",
    "        #Industrials: XLI\n",
    "        #Materials: XLB\n",
    "        #Real Estate: XLRE\n",
    "        #Technology: XLK\n",
    "        #Utilities: XLU\n",
    "\n",
    "        self.tickers = [\"^GSPC\"]\n",
    "\n",
    "    # Check whether 'start_date' and 'end_date' make a valid date range or not\n",
    "    def check_date_range(self, start_date: tuple, end_date: tuple):\n",
    "        start = datetime(*start_date)\n",
    "        end = datetime(*end_date)\n",
    "\n",
    "        if end <= start:\n",
    "            raise Exception(\"The start date must be before the end date!\")\n",
    "\n",
    "        return start, end\n",
    "\n",
    "    # Doanload prices using yfinance\n",
    "    def download_prices(self, start_date, end_date, interval='1d', column='Adj Close'):\n",
    "        self.start_date, self.end_date = self.check_date_range(start_date, end_date)\n",
    "        self.raw_prices = yf.download(self.tickers, start=self.start_date, end=self.end_date, interval=interval)\n",
    "\n",
    "    # Helper function to write dataframes on files with specified names\n",
    "    def write_on_disk(self, data: DataFrame, filename: str):\n",
    "        if \"csv\" in filename:\n",
    "            data.to_csv('Data/' + filename)\n",
    "        elif \"h5\" in filename:\n",
    "            data.to_hdf('Data/' + filename, 'fixed', mode='w', complib='blosc', complevel=9)\n",
    "\n",
    "        print(f\"Saved: Data/{filename}\")\n",
    "    \n",
    "    # Return a list of stock names in S&P 500 index\n",
    "    def get_ticker_list(self):\n",
    "        return self.tickers.copy()\n",
    "\n",
    "    # Return raw prices data (which is not cleaned)\n",
    "    def get_raw_prices(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
    "        #self.download_prices(start_date, end_date, interval=interval)\n",
    "        self.download_prices(start_date, end_date)\n",
    "        if save_as_csv:\n",
    "            #self.write_on_disk(self.raw_prices, \"US 10 year Treasury-raw_prices.csv\")\n",
    "            self.write_on_disk(self.raw_prices, \"new_S&P500-raw_prices.csv\")\n",
    "            #self.write_on_disk(self.raw_prices, \"new_Nasdaq-raw_prices.csv\")\n",
    "            #self.write_on_disk(self.raw_prices, \"new_Russell 2000-raw_prices.csv\")\n",
    "            #self.write_on_disk(self.raw_prices, \"new_Dow-Jones-raw_prices.csv\")\n",
    "            #self.write_on_disk(self.raw_prices, \"new_S&P500ShortTerm-raw_prices.csv\")\n",
    "            #self.write_on_disk(self.raw_prices, \"new_NasdaqShortTerm-raw_prices.csv\")\n",
    "        #if save_as_h5:\n",
    "        #    self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.h5\")\n",
    "\n",
    "        return self.raw_prices\n",
    "\n",
    "    # Calculate and return raw returns data (which is not cleaned)\n",
    "    def get_raw_returns(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
    "        self.get_raw_prices(start_date, end_date)\n",
    "\n",
    "        self.raw_returns = self.raw_prices.copy()\n",
    "        self.raw_returns = np.log(self.raw_returns).diff()\n",
    "        self.raw_returns = self.raw_returns.iloc[1:]  # removes first row which is NaN after diff()\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.h5\")\n",
    "\n",
    "        return self.raw_returns\n",
    "\n",
    "    # Return cleaned prices data (stocks with at least on NAN value are excluded)\n",
    "    def get_cleaned_prices(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
    "        self.get_raw_prices(start_date, end_date)\n",
    "\n",
    "        self.cleaned_prices = self.raw_prices.copy()\n",
    "        # Remove companies (columns) with all missing values for whole time range\n",
    "        self.cleaned_prices.dropna(axis='columns', how='all', inplace=True)\n",
    "        # Remove days (rows) with missing values for all of companies\n",
    "        self.cleaned_prices.dropna(axis='index', how='all', inplace=True)\n",
    "        # Finally, remove the columns with at least one Nan (missing value)\n",
    "        self.cleaned_prices.dropna(axis='columns', how='any', inplace=True)\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.self.cleaned_prices, \"S&P500-cleaned_prices.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.self.cleaned_prices, \"S&P500-cleaned_prices.h5\")\n",
    "\n",
    "        return self.cleaned_prices\n",
    "\n",
    "    # Calculate return values using cleaned data, and return the dataframe\n",
    "    def get_cleaned_returns(self, start_date: tuple, end_date: tuple, interval='1d', column='Adj Close', save_as_h5=False, save_as_csv=False):\n",
    "        self.get_cleaned_prices(start_date, end_date)\n",
    "\n",
    "        self.cleaned_returns = self.cleaned_prices.copy()\n",
    "        self.cleaned_returns = np.log(self.cleaned_returns).diff()\n",
    "        self.cleaned_returns = self.cleaned_returns.iloc[1:]  # removes first row which is NaN after diff()\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.h5\")\n",
    "\n",
    "        return self.cleaned_returns\n",
    "\n",
    "    # Return the last values for raw prices without redownloading them\n",
    "    def get_last_raw_prices(self, save_as_h5=False, save_as_csv=False):\n",
    "        if self.raw_prices is None:\n",
    "            return None\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.raw_prices, \"S&P500-raw_prices.h5\")\n",
    "\n",
    "        return self.raw_prices\n",
    "\n",
    "    # Return the last values for raw returns without redownloading them\n",
    "    def get_last_raw_returns(self, save_as_h5=False, save_as_csv=False):\n",
    "        if self.raw_returns is None:\n",
    "            return None\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.raw_returns, \"S&P500-raw_returns.h5\")\n",
    "\n",
    "        return self.raw_returns\n",
    "\n",
    "    # Return the last values for cleaned prices without redownloading them\n",
    "    def get_last_cleaned_prices(self, save_as_h5=False, save_as_csv=False):\n",
    "        if self.cleaned_prices is None:\n",
    "            return None\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.cleaned_prices, \"S&P500-cleaned_prices.h5\")\n",
    "\n",
    "        return self.cleaned_prices\n",
    "\n",
    "    # Return the last values for cleaned returns without redownloading them\n",
    "    def get_last_cleaned_returns(self, save_as_h5=False, save_as_csv=False):\n",
    "        if self.cleaned_returns is None:\n",
    "            return None\n",
    "\n",
    "        if save_as_csv:\n",
    "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.csv\")\n",
    "        if save_as_h5:\n",
    "            self.write_on_disk(self.cleaned_returns, \"S&P500-cleaned_returns.h5\")\n",
    "\n",
    "        return self.cleaned_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMM95YYPno_z",
    "outputId": "3dcfbd4b-8d68-402f-f654-11aa249c8691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Data/new_Nasdaq-raw_prices.csv\n",
      "--------------------------------------------\n",
      "Price            Close        High         Low        Open Volume\n",
      "Ticker           ^IXIC       ^IXIC       ^IXIC       ^IXIC  ^IXIC\n",
      "Date                                                             \n",
      "1971-02-05  100.000000  100.000000  100.000000  100.000000      0\n",
      "1971-02-08  100.839996  100.839996  100.839996  100.839996      0\n",
      "1971-02-09  100.760002  100.760002  100.760002  100.760002      0\n",
      "1971-02-10  100.690002  100.690002  100.690002  100.690002      0\n",
      "1971-02-11  101.449997  101.449997  101.449997  101.449997      0\n",
      "1971-02-12  102.050003  102.050003  102.050003  102.050003      0\n",
      "1971-02-16  102.190002  102.190002  102.190002  102.190002      0\n",
      "1971-02-17  101.739998  101.739998  101.739998  101.739998      0\n",
      "1971-02-18  101.419998  101.419998  101.419998  101.419998      0\n",
      "1971-02-19  100.699997  100.699997  100.699997  100.699997      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "# Driver code for testing purpose\n",
    "print(yf.__version__)\n",
    "if __name__ == '__main__':\n",
    "    data_downloader_object = SP500DataLoader()\n",
    "\n",
    "    # Get cleaned return values\n",
    "    cleaned_returns = data_downloader_object.get_raw_prices(\n",
    "        start_date=(1957, 1, 1), end_date=(2030, 9, 10),\n",
    "        #start_date=(2023, 2, 20), end_date=(2033, 1, 1),\n",
    "        #interval='60m', \n",
    "        column='Adj Close', \n",
    "        save_as_h5=True, save_as_csv=True\n",
    "    )\n",
    "\n",
    "    # Print a part of the dataframe of cleaned returns\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(cleaned_returns.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "S&P500 Data Loader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
